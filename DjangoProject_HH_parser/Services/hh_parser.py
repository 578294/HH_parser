import requests
import time
import os
import django
import sys
from django.utils import timezone
from hhparser.models import Vacancy

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'DjangoProject_HH_parser.settings')
django.setup()

USER_AGENT = "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 YaBrowser/25.6.0.0 Safari/537.36"


class HHApiParser:
    def __init__(self):
        self.base_url = "https://api.hh.ru/vacancies"
        self.session = requests.Session()
        self.session.headers.update({'user-agent': USER_AGENT, 'HH-User-Agent': 'HH Parser App'})

    def parse_vacancies(self, search_query="Python", vacancy_count=50):
        all_vacancies = []
        page = 0
        per_page = min(50, vacancy_count)  # –ú–∞–∫—Å–∏–º—É–º 50 –≤–∞–∫–∞–Ω—Å–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤ API
        if vacancy_count > 500:
            vacancy_count = 500

        while len(all_vacancies) < vacancy_count:
            print(f"–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page + 1}, —Å–æ–±—Ä–∞–Ω–æ {len(all_vacancies)}/{vacancy_count} –≤–∞–∫–∞–Ω—Å–∏–π")

            params = {
                'text': search_query,
                'page': page,
                'per_page': per_page,
                'area': 1,  # –ú–æ—Å–∫–≤–∞
                'only_with_salary': False,
            }

            try:
                response = self.session.get(self.base_url, params=params, timeout=15)
                response.raise_for_status()
                data = response.json()

                if 'items' not in data or not data['items']:
                    print(f"–ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page + 1} –Ω–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–π")
                    break

                for vacancy_data in data['items']:
                    if len(all_vacancies) >= vacancy_count:
                        break

                    try:
                        vacancy = self.parse_vacancy_item(vacancy_data)
                        if vacancy:
                            all_vacancies.append(vacancy)
                    except Exception as e:
                        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
                        continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –µ—â–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                if page >= data['pages'] - 1:
                    print("–î–æ—Å—Ç–∏–≥–Ω—É—Ç –∫–æ–Ω–µ—Ü —Å–ø–∏—Å–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π")
                    break

                page += 1
                time.sleep(0.5)  # –£–≤–∞–∂–∞–µ–º API HH.ru

            except requests.exceptions.RequestException as e:
                print(f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}")
                break
            except Exception as e:
                print(f"–û–±—â–∞—è –æ—à–∏–±–∫–∞: {e}")
                continue

        print(f"–í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(all_vacancies)}")
        return all_vacancies

    def parse_vacancy_item(self, vacancy_data):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–¥–µ–ª—å–Ω–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥–∞–Ω–Ω—ã—Ö"""

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not vacancy_data.get('name') or not vacancy_data.get('alternate_url'):
            print(f"‚ùå –ü—Ä–æ–ø—É—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–∏: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
            return None

        experience_map = {
            'noExperience': 'no',
            'between1And3': '1-3',
            'between3And6': '3-6',
            'moreThan6': '6+'
        }

        employment_map = {
            'full': 'full',
            'part': 'part',
            'remote': 'remote',
            'project': 'project'
        }

        experience = experience_map.get(vacancy_data.get('experience', {}).get('id'), 'no')
        employment = employment_map.get(vacancy_data.get('employment', {}).get('id'), 'full')

        description = self.get_full_description(vacancy_data.get('url'))

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–∞–≤—ã–∫–∏
        skills_text = ', '.join([skill['name'] for skill in vacancy_data.get('key_skills', [])])
        if len(skills_text) > 1000:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
            skills_text = skills_text[:1000] + "..."

        vacancy_info = {
            'title': vacancy_data.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è').strip(),
            'company': vacancy_data.get('employer', {}).get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ').strip(),
            'salary': self.parse_salary(vacancy_data.get('salary')),
            'description': description,
            'experience': experience,
            'employment': employment,
            'skills': skills_text,
            'link': vacancy_data.get('alternate_url', '').strip(),
        }

        return vacancy_info

    def get_full_description(self, vacancy_url):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏"""
        if not vacancy_url:
            return ""

        try:
            response = self.session.get(vacancy_url, timeout=10)
            response.raise_for_status()
            data = response.json()
            description = data.get('description', '')
            import re
            clean_description = re.sub('<[^<]+?>', '', description)
            return clean_description[:1500]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É

        except Exception as e:
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {e}")
            return ""

    def parse_salary(self, salary_data):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞—Ä–ø–ª–∞—Ç—ã"""
        if not salary_data:
            return "–ù–µ —É–∫–∞–∑–∞–Ω–∞"

        salary_from = salary_data.get('from')
        salary_to = salary_data.get('to')
        currency = '‚ÇΩ' if salary_data.get('currency') == 'RUR' else salary_data.get('currency', '')

        if salary_from and salary_to:
            return f"{salary_from:,} - {salary_to:,} {currency}".replace(',', ' ')
        elif salary_from:
            return f"–æ—Ç {salary_from:,} {currency}".replace(',', ' ')
        elif salary_to:
            return f"–¥–æ {salary_to:,} {currency}".replace(',', ' ')
        else:
            return "–ù–µ —É–∫–∞–∑–∞–Ω–∞"

    def save_to_database(self, vacancies):
        saved_count = 0
        updated_count = 0
        skipped_count = 0

        for vacancy_info in vacancies:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                if not vacancy_info.get('title'):
                    print(f"‚ùå –ü—Ä–æ–ø—É—Å–∫: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ")
                    skipped_count += 1
                    continue

                if not vacancy_info.get('link'):
                    print(f"‚ùå –ü—Ä–æ–ø—É—Å–∫ '{vacancy_info.get('title', '')}': –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Å—ã–ª–∫–∞")
                    skipped_count += 1
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å—Å—ã–ª–∫–∏
                if not vacancy_info['link'].startswith('http'):
                    print(f"‚ùå –ü—Ä–æ–ø—É—Å–∫ '{vacancy_info['title']}': –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Å—ã–ª–∫–∞ '{vacancy_info['link']}'")
                    skipped_count += 1
                    continue

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                vacancy_data = {
                    'title': vacancy_info.get('title', '').strip(),
                    'company': vacancy_info.get('company', '').strip(),
                    'salary': vacancy_info.get('salary', '–ù–µ —É–∫–∞–∑–∞–Ω–∞'),
                    'description': vacancy_info.get('description', ''),
                    'experience': vacancy_info.get('experience', 'no'),
                    'employment': vacancy_info.get('employment', 'full'),
                    'skills': vacancy_info.get('skills', ''),
                }

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ–º
                obj, created = Vacancy.objects.update_or_create(
                    link=vacancy_info['link'].strip(),
                    defaults=vacancy_data
                )

                if created:
                    saved_count += 1
                    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {vacancy_info['title'][:60]}...")
                else:
                    updated_count += 1
                    print(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∞: {vacancy_info['title'][:60]}...")

            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è '{vacancy_info.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}': {e}")
                skipped_count += 1
                continue

        print(f"üìä –ò—Ç–æ–≥: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count}, –æ–±–Ω–æ–≤–ª–µ–Ω–æ {updated_count}, –ø—Ä–æ–ø—É—â–µ–Ω–æ {skipped_count}")
        total_processed = saved_count + updated_count
        return total_processed