"""
–ú–æ–¥—É–ª—å hh_parser.py —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª–∞—Å—Å HHApiParser –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∞–∫–∞–Ω—Å–∏–π —Å HeadHunter API.

–û—Å–Ω–æ–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
- –ü–∞—Ä—Å–∏–Ω–≥ –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ –ø–æ–∏—Å–∫–æ–≤—ã–º –∑–∞–ø—Ä–æ—Å–∞–º
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ API –∏ —Å–µ—Ç–µ–≤—ã—Ö —Å–±–æ–µ–≤
"""

import requests
import time
import os
import django
import sys
import re
from django.utils import timezone
from hhparser.models import Vacancy

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Django –æ–∫—Ä—É–∂–µ–Ω–∏—è
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'DjangoProject_HH_parser.settings')
django.setup()

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
USER_AGENT = "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 YaBrowser/25.6.0.0 Safari/537.36"
BASE_API_URL = "https://api.hh.ru/vacancies"


class HHApiParser:
    """
    –ü–∞—Ä—Å–µ—Ä –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å API HeadHunter –∏ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ –≤–∞–∫–∞–Ω—Å–∏—è—Ö.

    –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–±–æ—Ä, –æ–±—Ä–∞–±–æ—Ç–∫—É –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π
    —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ API.
    """

    def __init__(self) -> None:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ HTTP-—Å–µ—Å—Å–∏–∏.

        –°–æ–∑–¥–∞–µ—Ç —Å–µ—Å—Å–∏—é requests —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
        –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å API HH.ru.
        """
        self.base_url = BASE_API_URL
        self.session = requests.Session()
        self.session.headers.update({
            'user-agent': USER_AGENT,
            'HH-User-Agent': 'HH Parser App'
        })

    def parse_vacancies(self, search_query: str = "Python", vacancy_count: int = 50) -> list:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º.

        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π API.
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–µ—Ç–µ–≤—ã–µ –æ—à–∏–±–∫–∏ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤.

        Args:
            search_query: str (–ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–π, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "Python")
            vacancy_count: int (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è, –º–∞–∫—Å–∏–º—É–º 500)

        Returns:
            list: —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ –≤–∞–∫–∞–Ω—Å–∏–π
        """
        all_vacancies = []
        page = 0
        per_page = min(50, vacancy_count)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤ API
        if vacancy_count > 500:
            vacancy_count = 500

        while len(all_vacancies) < vacancy_count:
            print(f"–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page + 1}, —Å–æ–±—Ä–∞–Ω–æ {len(all_vacancies)}/{vacancy_count} –≤–∞–∫–∞–Ω—Å–∏–π")

            params = {
                'text': search_query,
                'page': page,
                'per_page': per_page,
                'area': 1,  # –ú–æ—Å–∫–≤–∞
                'only_with_salary': False,
            }

            try:
                response = self.session.get(self.base_url, params=params, timeout=15)
                response.raise_for_status()
                data = response.json()

                if 'items' not in data or not data['items']:
                    print(f"–ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page + 1} –Ω–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–π")
                    break

                for vacancy_data in data['items']:
                    if len(all_vacancies) >= vacancy_count:
                        break

                    try:
                        vacancy = self.parse_vacancy_item(vacancy_data)
                        if vacancy:
                            all_vacancies.append(vacancy)
                    except Exception as e:
                        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
                        continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –µ—â–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                if page >= data['pages'] - 1:
                    print("–î–æ—Å—Ç–∏–≥–Ω—É—Ç –∫–æ–Ω–µ—Ü —Å–ø–∏—Å–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π")
                    break

                page += 1
                time.sleep(0.5)  # –£–≤–∞–∂–∞–µ–º API HH.ru

            except requests.exceptions.RequestException as e:
                print(f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}")
                break
            except Exception as e:
                print(f"–û–±—â–∞—è –æ—à–∏–±–∫–∞: {e}")
                continue

        print(f"–í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(all_vacancies)}")
        return all_vacancies

    def parse_vacancy_item(self, vacancy_data: dict) -> dict:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–¥–µ–ª—å–Ω–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –µ–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç.

        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ–¥–Ω–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏, –∏–∑–≤–ª–µ–∫–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞–Ω–Ω—ã—Ö –≤ –µ–¥–∏–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.

        Args:
            vacancy_data: dict (—Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –æ—Ç API)

        Returns:
            dict: —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not vacancy_data.get('name') or not vacancy_data.get('alternate_url'):
            print(f"‚ùå –ü—Ä–æ–ø—É—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–∏: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
            return None

        experience_map = {
            'noExperience': 'no',
            'between1And3': '1-3',
            'between3And6': '3-6',
            'moreThan6': '6+'
        }

        employment_map = {
            'full': 'full',
            'part': 'part',
            'remote': 'remote',
            'project': 'project'
        }

        experience = experience_map.get(vacancy_data.get('experience', {}).get('id'), 'no')
        employment = employment_map.get(vacancy_data.get('employment', {}).get('id'), 'full')
        description = self.get_full_description(vacancy_data.get('url'))

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–∞–≤—ã–∫–∏
        skills_text = ', '.join([skill['name'] for skill in vacancy_data.get('key_skills', [])])
        if len(skills_text) > 1000:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
            skills_text = skills_text[:1000] + "..."

        vacancy_info = {
            'title': vacancy_data.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è').strip(),
            'company': vacancy_data.get('employer', {}).get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ').strip(),
            'salary': self.parse_salary(vacancy_data.get('salary')),
            'description': description,
            'experience': experience,
            'employment': employment,
            'skills': skills_text,
            'link': vacancy_data.get('alternate_url', '').strip(),
        }

        return vacancy_info

    def get_full_description(self, vacancy_url: str) -> str:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ URL.

        –í—ã–ø–æ–ª–Ω—è–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è
        –≤–∞–∫–∞–Ω—Å–∏–∏ –∏ –æ—á–∏—â–∞–µ—Ç HTML-—Ä–∞–∑–º–µ—Ç–∫—É.

        Args:
            vacancy_url: str (URL –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è)

        Returns:
            str: –æ—á–∏—â–µ–Ω–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏
        """
        if not vacancy_url:
            return ""

        try:
            response = self.session.get(vacancy_url, timeout=10)
            response.raise_for_status()
            data = response.json()
            description = data.get('description', '')
            clean_description = re.sub('<[^<]+?>', '', description)
            return clean_description[:1500]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É

        except Exception as e:
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {e}")
            return ""

    def parse_salary(self, salary_data: dict) -> str:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞—Ä–ø–ª–∞—Ç–µ.

        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –∑–∞—Ä–ø–ª–∞—Ç–µ –∏–∑ API –≤ —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ –∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≤–∞–ª—é—Ç.

        Args:
            salary_data: dict (–¥–∞–Ω–Ω—ã–µ –æ –∑–∞—Ä–ø–ª–∞—Ç–µ –æ—Ç API)

        Returns:
            str: –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∑–∞—Ä–ø–ª–∞—Ç–µ
        """
        if not salary_data:
            return "–ù–µ —É–∫–∞–∑–∞–Ω–∞"

        salary_from = salary_data.get('from')
        salary_to = salary_data.get('to')
        currency = '‚ÇΩ' if salary_data.get('currency') == 'RUR' else salary_data.get('currency', '')

        if salary_from and salary_to:
            return f"{salary_from:,} - {salary_to:,} {currency}".replace(',', ' ')
        elif salary_from:
            return f"–æ—Ç {salary_from:,} {currency}".replace(',', ' ')
        elif salary_to:
            return f"–¥–æ {salary_to:,} {currency}".replace(',', ' ')
        else:
            return "–ù–µ —É–∫–∞–∑–∞–Ω–∞"

    def save_to_database(self, vacancies: list) -> int:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–π –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏.

        –í—ã–ø–æ–ª–Ω—è–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç/–æ–±–Ω–æ–≤–ª—è–µ—Ç –∑–∞–ø–∏—Å–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.
        –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–µ–π –ø–æ —Å—Å—ã–ª–∫–µ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é.

        Args:
            vacancies: list (—Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ –≤–∞–∫–∞–Ω—Å–∏–π)

        Returns:
            int: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π
        """
        saved_count = 0
        updated_count = 0
        skipped_count = 0

        for vacancy_info in vacancies:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                if not vacancy_info.get('title'):
                    print(f"‚ùå –ü—Ä–æ–ø—É—Å–∫: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ")
                    skipped_count += 1
                    continue

                if not vacancy_info.get('link'):
                    print(f"‚ùå –ü—Ä–æ–ø—É—Å–∫ '{vacancy_info.get('title', '')}': –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Å—ã–ª–∫–∞")
                    skipped_count += 1
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å—Å—ã–ª–∫–∏
                if not vacancy_info['link'].startswith('http'):
                    print(f"‚ùå –ü—Ä–æ–ø—É—Å–∫ '{vacancy_info['title']}': –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Å—ã–ª–∫–∞ '{vacancy_info['link']}'")
                    skipped_count += 1
                    continue

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                vacancy_data = {
                    'title': vacancy_info.get('title', '').strip(),
                    'company': vacancy_info.get('company', '').strip(),
                    'salary': vacancy_info.get('salary', '–ù–µ —É–∫–∞–∑–∞–Ω–∞'),
                    'description': vacancy_info.get('description', ''),
                    'experience': vacancy_info.get('experience', 'no'),
                    'employment': vacancy_info.get('employment', 'full'),
                    'skills': vacancy_info.get('skills', ''),
                }

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ–º
                obj, created = Vacancy.objects.update_or_create(
                    link=vacancy_info['link'].strip(),
                    defaults=vacancy_data
                )

                if created:
                    saved_count += 1
                    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {vacancy_info['title'][:60]}...")
                else:
                    updated_count += 1
                    print(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∞: {vacancy_info['title'][:60]}...")

            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è '{vacancy_info.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}': {e}")
                skipped_count += 1
                continue

        print(f"üìä –ò—Ç–æ–≥: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count}, –æ–±–Ω–æ–≤–ª–µ–Ω–æ {updated_count}, –ø—Ä–æ–ø—É—â–µ–Ω–æ {skipped_count}")
        total_processed = saved_count + updated_count
        return total_processed